{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "# torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from l5kit.data import LocalDataManager, ChunkedDataset\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.evaluation import write_pred_csv, compute_metrics_csv, read_gt_csv, write_gt_csv\n",
    "from l5kit.evaluation.metrics import neg_multi_log_likelihood, time_displace\n",
    "from l5kit.geometry import transform_points\n",
    "from l5kit.visualization import PREDICTED_POINTS_COLOR, TARGET_POINTS_COLOR, draw_trajectory\n",
    "from l5kit.dataset import AgentDataset\n",
    "from l5kit.geometry import transform_point, transform_points\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import l5kit\n",
    "import torch\n",
    "\n",
    "import os\n",
    "\n",
    "from l5kit.data import ChunkedDataset, LocalDataManager\n",
    "from l5kit.rasterization import build_rasterizer\n",
    "from l5kit.dataset import EgoDataset, AgentDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torch import nn, optim\n",
    "from torchvision.models.resnet import resnet18, resnet50, resnet34\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'format_version': 4,\n",
    "    'model_params': {\n",
    "        'history_num_frames': 10,\n",
    "        'history_step_size': 1,\n",
    "        'history_delta_time': 0.1,\n",
    "        'future_num_frames': 50,\n",
    "        'future_step_size': 1,\n",
    "        'future_delta_time': 0.1\n",
    "    },\n",
    "    \n",
    "    'raster_params': {\n",
    "        'raster_size': [300, 300],\n",
    "        'pixel_size': [0.5, 0.5],\n",
    "        'ego_center': [0.25, 0.5],\n",
    "        'map_type': 'py_semantic',\n",
    "        'satellite_map_key': 'aerial_map/aerial_map.png',\n",
    "        'semantic_map_key': 'semantic_map/semantic_map.pb',\n",
    "        'dataset_meta_key': 'meta.json',\n",
    "        'filter_agents_threshold': 0.5\n",
    "    },\n",
    "    \n",
    "    'test_data_loader': {\n",
    "        'key': 'scenes/test.zarr',\n",
    "        'batch_size': 8,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 2\n",
    "    },\n",
    "    \n",
    "    'train_data_loader': {\n",
    "        'key': 'scenes/train.zarr',\n",
    "        'batch_size': 8,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 2\n",
    "    },\n",
    "    \n",
    "    'val_data_loader': {\n",
    "        'key': 'scenes/validate.zarr',\n",
    "        'batch_size': 64,\n",
    "        'shuffle': False,\n",
    "        'num_workers': 2\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34maerial_map\u001b[0m/                       \u001b[01;34mscenes\u001b[0m/\r\n",
      "meta.json                         \u001b[01;34msemantic_map\u001b[0m/\r\n",
      "multi_mode_sample_submission.csv  single_mode_sample_submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls /root/input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_INPUT = \"/root/input\"\n",
    "os.environ[\"L5KIT_DATA_FOLDER\"] = DIR_INPUT\n",
    "dm = LocalDataManager(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterizer = build_rasterizer(cfg, dm)\n",
    "\n",
    "train_zarr = ChunkedDataset(dm.require(cfg['train_data_loader'][\"key\"])).open()\n",
    "train_dataset = AgentDataset(cfg, train_zarr, rasterizer)\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                             shuffle=False,\n",
    "                             batch_size=8,\n",
    "                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_zarr = ChunkedDataset(dm.require(cfg['val_data_loader'][\"key\"])).open()\n",
    "val_dataset = AgentDataset(cfg, val_zarr, rasterizer)\n",
    "val_dataloader = DataLoader(val_dataset,\n",
    "                             shuffle=False,\n",
    "                             batch_size=8,\n",
    "                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LyftModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = resnet34(pretrained=True)\n",
    "        \n",
    "        num_history_channels = (cfg[\"model_params\"][\"history_num_frames\"] + 1) * 2\n",
    "        num_in_channels = 3 + num_history_channels\n",
    "\n",
    "        self.backbone.conv1 = nn.Conv2d(\n",
    "            num_in_channels,\n",
    "            self.backbone.conv1.out_channels,\n",
    "            kernel_size=self.backbone.conv1.kernel_size,\n",
    "            stride=self.backbone.conv1.stride,\n",
    "            padding=self.backbone.conv1.padding,\n",
    "            bias=False,\n",
    "        )\n",
    "        \n",
    "        # This is 512 for resnet18 and resnet34;\n",
    "        # And it is 2048 for the other resnets\n",
    "        backbone_out_features = 512\n",
    "        \n",
    "        # X, Y coords for the future positions (output shape: Bx50x2)\n",
    "        num_targets = 2 * cfg[\"model_params\"][\"future_num_frames\"]\n",
    "\n",
    "        # You can add more layers here.\n",
    "        self.head = nn.Sequential(\n",
    "            # nn.Dropout(0.2),\n",
    "            nn.Linear(in_features=backbone_out_features, out_features=4096),\n",
    "        )\n",
    "\n",
    "        self.logit = nn.Linear(4096, out_features=num_targets)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "\n",
    "        x = self.backbone.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.head(x)\n",
    "        x = self.logit(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2b2db9159a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compiling model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLyftModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# compiling model\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = LyftModel(cfg).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss(reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_transform_points(points: torch.Tensor, transf_matrix: torch.Tensor) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        points (torch.Tensor): Input points (BxNx2) or (BxNx3).\n",
    "        transf_matrix (torch.Tensor): Bx3x3 or Bx4x4 transformation matrix for 2D and 3D input respectively\n",
    "    Returns:\n",
    "        torch.Tensor: array of shape (B,N,2) for 2D input points, or (B,N,3) points for 3D input points\n",
    "    \"\"\"\n",
    "    assert len(points.shape) == len(transf_matrix.shape) == 3\n",
    "    assert transf_matrix.shape[1] == transf_matrix.shape[2]\n",
    "\n",
    "    if points.shape[2] not in [2, 3]:\n",
    "        raise AssertionError(\"Points input should be (B, N, 2) or (B, N,3) shape, received {}\".format(points.shape))\n",
    "\n",
    "    assert points.shape[2] == transf_matrix.shape[2] - 1, \"points dim should be one less than matrix dim\"\n",
    "\n",
    "    num_dims = len(transf_matrix[0]) - 1\n",
    "\n",
    "    transf_matrix = transf_matrix.transpose(1, 2)\n",
    "    # print(points.shape, transf_matrix.shape)\n",
    "\n",
    "    # print(torch.bmm(points, transf_matrix[:, :num_dims, :num_dims]).shape)\n",
    "    # print(transf_matrix[:, -1:-1, :num_dims].shape)\n",
    "    return torch.bmm(points, transf_matrix[:, :num_dims, :num_dims]) + transf_matrix[:, -1, :num_dims].reshape(len(transf_matrix), 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sane\n"
     ]
    }
   ],
   "source": [
    "print('sane')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f893fc54dea43188e3b862c28cfc683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "val_loss: tensor(41.6918, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(201.5102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(468.9590, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(527.1396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.7245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(20.5325, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(19.5741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(12.0080, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(58.4329, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(59.2424, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(22.3108, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(6.3227, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.8284, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(33.1745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(94.1429, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(165.4750, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1258.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(28.9751, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(20.0268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(9.7864, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(8.1173, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(732.2079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2049.3843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1685.5720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(4079.9824, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1049.9250, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2528.1074, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1361.8831, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1842.6653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(308.4921, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(43.8894, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(210.9905, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(872.5579, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(688.1845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(357.3303, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(620.8145, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(152.9621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(33.8511, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(5.6816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(228.2488, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(80.6373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(27.5472, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(12.0868, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(11.0103, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(44.0789, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(60.8358, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(74.7966, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(216.2043, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(669.9725, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1121.4498, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(568.3867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(6208.4897, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(788.9079, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(242.4811, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(814.9597, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(352.3705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(15.6684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(443.5020, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(894.5642, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1292.9050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(43.5285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(46.7088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(200.2495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1313.1493, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(152.9553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(126.2577, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(78.5105, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.5202, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(61.9960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(16.3292, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(114.4930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(19.7621, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(23.0892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(13.2948, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(42.2336, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(310.0230, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(131.2357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(392.4594, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(53.9956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(594.8580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1046.9592, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1915.4874, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(4335.2056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(429.8683, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1257.2281, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(102.7062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(365.0116, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(192.3267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(147.0783, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(245.2586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.5185, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2.0214, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(8.6062, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(47.6009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(53.4148, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(223.0439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(115.2327, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(862.9862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3216.0754, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tr_it = iter(train_dataloader)\n",
    "val_it = iter(val_dataloader)\n",
    "\n",
    "val_data = next(val_it)\n",
    "\n",
    "progress_bar = tqdm(range(10000))\n",
    "\n",
    "losses_train = []\n",
    "\n",
    "print('starting')\n",
    "\n",
    "for iter_ind in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    # forward pass\n",
    "    inputs = data[\"image\"].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "    targets = batch_transform_points(data[\"target_positions\"].float().to(device), data[\"raster_from_agent\"].float().to(device))\n",
    "    \n",
    "    outputs = model(inputs).reshape(targets.shape)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # not all the output steps are valid, but we can filter them out from the loss using availabilities\n",
    "    loss = loss * target_availabilities\n",
    "    loss = loss.mean()\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iter_ind % 100 == 0 and iter_ind != 0:\n",
    "        val_inputs = val_data[\"image\"].to(device)\n",
    "        val_target_availabilities = val_data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "        val_targets = batch_transform_points(val_data[\"target_positions\"].float().to(device), val_data[\"raster_from_agent\"].float().to(device))\n",
    "\n",
    "        val_outputs = model(val_inputs).reshape(val_targets.shape)\n",
    "        val_loss = criterion(val_outputs, val_targets)\n",
    "        \n",
    "        # not all the output steps are valid, but we can filter them out from the loss using availabilities\n",
    "        val_loss = val_loss * val_target_availabilities\n",
    "        val_loss = val_loss.mean()\n",
    "        \n",
    "        print('val_loss:', val_loss)\n",
    "        \n",
    "        \n",
    "\n",
    "    losses_train.append(loss.item())\n",
    "    progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'resnet_34_10k_steps_vast_ai_oct_1_2020.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c367e29bbd64e1ea748726147dfe0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting\n",
      "val_loss: tensor(454.5845, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(41.3200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(23.3031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(54.0553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.9521, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(172.2762, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(12.2942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(21.0516, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(16.5225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(379.8189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(22.6089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(136.2099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(629.7614, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(147.2047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(8.8009, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(9.2982, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(6.0550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(5.0557, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(59.4163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(9.7730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(8.1379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(33.8373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(293.3757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(172.7730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(44.3104, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(31.7792, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(137.2008, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(40.5684, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(19.2879, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(4.7550, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.7930, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(4.7127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(7.4468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.6132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(6.9404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(87.0125, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(76.1639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(14.4816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(27.9524, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(8.6768, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(8.9742, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(12.5709, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(53.0927, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(25.1188, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(29.8528, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(19.8377, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.8474, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(13.8205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(6.8872, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(68.2439, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(107.9047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(41.1778, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.8766, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2.6666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2.7170, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2.9867, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.1310, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(28.9892, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(133.3179, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(4.7863, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(48.7205, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(29.4099, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.8113, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(13.2722, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(20.5384, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(33.4747, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.4446, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.0299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(13.8702, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(52.3391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(6.9782, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2.1228, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.2523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(5.8035, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1.4458, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(0.9628, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(12.9546, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(6.2331, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(4.0689, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1.9299, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.1464, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(1.6852, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(2.4056, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(4.9959, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(14.4140, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(278.8873, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(133.3765, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(18.7888, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(5.4639, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(10.6843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(23.0268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(7.0926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.8537, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.0846, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.6385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(3.0796, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(5.3278, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(8.0120, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "val_loss: tensor(17.0807, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(10000))\n",
    "\n",
    "losses_train = []\n",
    "\n",
    "print('starting')\n",
    "\n",
    "for iter_ind in progress_bar:\n",
    "    try:\n",
    "        data = next(tr_it)\n",
    "    except StopIteration:\n",
    "        tr_it = iter(train_dataloader)\n",
    "        data = next(tr_it)\n",
    "    model.train()\n",
    "    torch.set_grad_enabled(True)\n",
    "    \n",
    "    # forward pass\n",
    "    inputs = data[\"image\"].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "    targets = batch_transform_points(data[\"target_positions\"].float().to(device), data[\"raster_from_agent\"].float().to(device))\n",
    "    \n",
    "    outputs = model(inputs).reshape(targets.shape)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # not all the output steps are valid, but we can filter them out from the loss using availabilities\n",
    "    loss = loss * target_availabilities\n",
    "    loss = loss.mean()\n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iter_ind % 100 == 0 and iter_ind != 0:\n",
    "        val_inputs = val_data[\"image\"].to(device)\n",
    "        val_target_availabilities = val_data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "        val_targets = batch_transform_points(val_data[\"target_positions\"].float().to(device), val_data[\"raster_from_agent\"].float().to(device))\n",
    "\n",
    "        val_outputs = model(val_inputs).reshape(val_targets.shape)\n",
    "        val_loss = criterion(val_outputs, val_targets)\n",
    "        \n",
    "        # not all the output steps are valid, but we can filter them out from the loss using availabilities\n",
    "        val_loss = val_loss * val_target_availabilities\n",
    "        val_loss = val_loss.mean()\n",
    "        \n",
    "        print('val_loss:', val_loss)\n",
    "        \n",
    "        \n",
    "\n",
    "    losses_train.append(loss.item())\n",
    "    progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'resnet_34_30k_oct_5th.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1802051 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "/usr/local/lib/python3.6/dist-packages/l5kit/dataset/agent.py:115: RuntimeWarning: disable_traffic_light_faces not found in config, this will raise an error in the future\n",
      "  return self.get_frame(scene_index, state_index, track_id=track_id)\n",
      "loss: 2.1246492862701416 loss(avg): 3.5395550462639047:   0%|          | 1344/1802051 [14:29<323:37:01,  1.55it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-4bfbc7d76706>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mlosses_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprogress_bar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#     if idx == 5:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1175\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    374\u001b[0m             \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m                 \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# store information for evaluation\n",
    "future_coords_offsets_pd = []\n",
    "timestamps = []\n",
    "\n",
    "agent_ids = []\n",
    "\n",
    "losses_val = []\n",
    "progress_bar = tqdm(validate_dataloader)\n",
    "for idx, data in enumerate(progress_bar):\n",
    "    \n",
    "#     if idx == 5:\n",
    "#         break\n",
    "    \n",
    "    inputs = data[\"image\"].to(device)\n",
    "    target_availabilities = data[\"target_availabilities\"].unsqueeze(-1).to(device)\n",
    "    targets = data[\"target_positions\"].to(device)\n",
    "\n",
    "    outputs = model(inputs).reshape(targets.shape)\n",
    "    \n",
    "    loss = criterion(outputs, targets)\n",
    "    loss = loss * target_availabilities\n",
    "    loss = loss.mean()\n",
    "    \n",
    "    losses_val.append(loss.item())\n",
    "    progress_bar.set_description(f\"loss: {loss.item()} loss(avg): {np.mean(losses_val)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
